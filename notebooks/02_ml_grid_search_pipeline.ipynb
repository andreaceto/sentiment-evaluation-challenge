{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8635e546",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import re\n",
    "\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import (\n",
    "    f1_score, confusion_matrix, roc_curve, roc_auc_score\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6f61c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Minimal cleaning for classical ML workflows:\n",
    "    - lowercase\n",
    "    - strip whitespace\n",
    "    - normalize spaces\n",
    "    - keep punctuation\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "\n",
    "    text = text.lower()\n",
    "    text = text.strip()\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    return text\n",
    "\n",
    "def deduplicate_reviews(df: pd.DataFrame, text_col: str, label_col: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Updated deduplication pipeline:\n",
    "\n",
    "    1. Clean text using ML-cleaning (lowercase + normalize);\n",
    "       this ensures identical texts compare correctly.\n",
    "    2. Group by cleaned text.\n",
    "    3. If group labels conflict → drop the entire group.\n",
    "    4. If group labels are consistent → keep ONE copy.\n",
    "\n",
    "    Returns a cleaned DataFrame.\n",
    "    \"\"\"\n",
    "\n",
    "    # Step 1 — Clean the text BEFORE grouping\n",
    "    df = df.copy()\n",
    "    df[\"_clean_text\"] = df[text_col].apply(clean_text)\n",
    "\n",
    "    keep_indices = []\n",
    "\n",
    "    grouped = df.groupby(\"_clean_text\")\n",
    "    for clean_txt, group in grouped:\n",
    "        unique_labels = group[label_col].unique()\n",
    "\n",
    "        if len(unique_labels) > 1:\n",
    "            # Conflict → remove whole group\n",
    "            continue\n",
    "\n",
    "        # Keep one example\n",
    "        keep_indices.append(group.index[0])\n",
    "\n",
    "    cleaned_df = df.loc[keep_indices].copy()\n",
    "    cleaned_df.drop(columns=[\"_clean_text\"], inplace=True)\n",
    "\n",
    "    return cleaned_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0425470c",
   "metadata": {},
   "source": [
    "## Loading, Cleaning and Deduplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e874c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = pd.read_excel(os.path.join(\"..\", \"data\", \"raw\", \"Allegato 1 - data_classification.xlsx\"))\n",
    "\n",
    "# Clean text for ML use\n",
    "df[\"clean_text\"] = df[\"Review\"].apply(clean_text)\n",
    "\n",
    "# Deduplicate using cleaned text + consistent label logic\n",
    "df = deduplicate_reviews(df, text_col=\"clean_text\", label_col=\"Promotore\")\n",
    "\n",
    "print(\"Final dataset size after dedupe:\", df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f999af",
   "metadata": {},
   "source": [
    "## Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58482df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[\"clean_text\"]\n",
    "y = df[\"Promotore\"]\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.20,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11fe8581",
   "metadata": {},
   "source": [
    "## Model Candidates and Search Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a7cbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Logistic Regression\n",
    "pipe_lr = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer(preprocessor=clean_text)),\n",
    "    (\"clf\", LogisticRegression(max_iter=1000, n_jobs=-1))\n",
    "])\n",
    "\n",
    "# Linear SVC\n",
    "pipe_svc = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer(preprocessor=clean_text)),\n",
    "    (\"clf\", LinearSVC())\n",
    "])\n",
    "\n",
    "# Stochastic Gradient Descent Classifier\n",
    "pipe_sgd = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer(preprocessor=clean_text)),\n",
    "    (\"clf\", SGDClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "pipelines = {\n",
    "    \"logreg\": pipe_lr,\n",
    "    \"svm\": pipe_svc,\n",
    "    \"sgd\": pipe_sgd\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0698a20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorizer hyperparameters\n",
    "tfidf_params = {\n",
    "    \"tfidf__ngram_range\": [(1,1), (1,2)],\n",
    "    \"tfidf__min_df\": [3, 5],\n",
    "    \"tfidf__max_df\": [0.90, 0.95],\n",
    "    \"tfidf__max_features\": [50_000, 100_000]\n",
    "}\n",
    "\n",
    "lr_params = {\n",
    "    **tfidf_params,\n",
    "    \"clf__C\": [0.5, 1.0, 2.0, 3.0],\n",
    "    \"clf__class_weight\": [None, \"balanced\"]\n",
    "}\n",
    "\n",
    "svc_params = {\n",
    "    **tfidf_params,\n",
    "    \"clf__C\": [0.5, 1.0, 2.0]\n",
    "}\n",
    "\n",
    "sgd_params = {\n",
    "    **tfidf_params,\n",
    "    \"clf__loss\": [\"log_loss\", \"hinge\"],\n",
    "    \"clf__alpha\": [1e-4, 1e-5],\n",
    "    \"clf__penalty\": [\"l2\", \"l1\", \"elasticnet\"]\n",
    "}\n",
    "\n",
    "param_grids = {\n",
    "    \"logreg\": lr_params,\n",
    "    \"svm\": svc_params,\n",
    "    \"sgd\": sgd_params\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27dcdc4b",
   "metadata": {},
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7144ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models = {}\n",
    "results = []\n",
    "\n",
    "for name in pipelines:\n",
    "    print(f\"\\n### Running search for {name} ###\")\n",
    "\n",
    "    search = RandomizedSearchCV(\n",
    "        estimator=pipelines[name],\n",
    "        param_distributions=param_grids[name],\n",
    "        n_iter=20,\n",
    "        scoring=\"f1\",\n",
    "        cv=3,\n",
    "        n_jobs=-1,\n",
    "        verbose=2,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    search.fit(X_train, y_train)\n",
    "\n",
    "    best_models[name] = search.best_estimator_\n",
    "    results.append({\n",
    "        \"model\": name,\n",
    "        \"best_score\": search.best_score_,\n",
    "        \"best_params\": search.best_params_\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f35cb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b04c085",
   "metadata": {},
   "source": [
    "## Evaluate Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf8d9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_name = max(results, key=lambda x: x[\"best_score\"])[\"model\"]\n",
    "best_model = best_models[best_name]\n",
    "\n",
    "print(\"Best model:\", best_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7038fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_model.predict(X_val)\n",
    "y_scores = (\n",
    "    best_model.decision_function(X_val)\n",
    "    if hasattr(best_model, \"decision_function\")\n",
    "    else best_model.predict_proba(X_val)[:,1]\n",
    ")\n",
    "\n",
    "f1 = f1_score(y_val, y_pred)\n",
    "auc = roc_auc_score(y_val, y_scores)\n",
    "cm = confusion_matrix(y_val, y_pred)\n",
    "\n",
    "print(\"Validation F1:\", f1)\n",
    "print(\"Validation AUC:\", auc)\n",
    "print(\"Confusion Matrix:\\n\", cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f478561d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Curve\n",
    "fpr, tpr, thresh = roc_curve(y_val, y_scores)\n",
    "plt.plot(fpr, tpr, label=f\"AUC={auc:.3f}\")\n",
    "plt.plot([0,1],[0,1],\"--\")\n",
    "plt.title(f\"ROC Curve — {best_name}\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85583817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(f\"Confusion Matrix — {best_name}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dcb93ba",
   "metadata": {},
   "source": [
    "## Save Best Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41de4691",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "\n",
    "# Output dir\n",
    "out_dir = os.path.join(\"..\", \"models\")\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "# Extract best params and model\n",
    "best_params = best_model[\"best_params\"]\n",
    "\n",
    "# Save best params (JSON)\n",
    "params_path = os.path.join(out_dir, f\"best_params_{best_name}.json\")\n",
    "with open(params_path, \"w\", encoding=\"utf-8\") as f:\n",
    "\tjson.dump(best_params, f, ensure_ascii=False, indent=2, default=str)\n",
    "\n",
    "# Save best model (Pickle)\n",
    "model_path = os.path.join(out_dir, f\"best_model_{best_name}.pkl\")\n",
    "with open(model_path, \"wb\") as f:\n",
    "\tpickle.dump(best_model, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "print(f\"Saved best params to: {params_path}\")\n",
    "print(f\"Saved best model to:  {model_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.10.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
